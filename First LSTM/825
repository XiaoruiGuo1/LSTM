import sys
import os
import math
from unicodedata import name
import numpy as np
import tensorflow as tf
from tensorflow import keras
from matplotlib import pyplot as plt


# Create the dataset of subsystems
u = np.zeros(1800)
x_1 = np.zeros(1801)
x_2 = np.zeros(1801)
x_3 = np.zeros(1801)
x_4 = np.zeros(1801)
x_5 = np.zeros(1801)
x_6 = np.zeros(1801)
x_7 = np.zeros(1801)
x_8 = np.zeros(1801)
x_9 = np.zeros(1801)
x_10 = np.zeros(1801)
x_11 = np.zeros(1801)
x_12 = np.zeros(1801)
x_13 = np.zeros(1801)
x_14 = np.zeros(1801)
x_15 = np.zeros(1801)
x_16 = np.zeros(1801)
x_17 = np.zeros(1801)
x_18 = np.zeros(1801)
x_19 = np.zeros(1801)
x_20 = np.zeros(1801)

i = 0
for i in range(1800):
       u[i] = np.sin(i*np.pi/20) 
       x_1[i + 1] = 0.9*x_1[i] + 2*u[i]
       x_2[i + 1] = 0.9*x_1[i] + 2*u[i]
       x_3[i + 1] = 0.9*x_1[i] + 2*u[i]
       x_4[i + 1] = 0.9*x_1[i] + 2*u[i]
       x_5[i + 1] = 0.9*x_1[i] + 2*u[i]
       x_6[i + 1] = 0.9*x_1[i] + 2*u[i]
       x_7[i + 1] = 0.9*x_1[i] + 2*u[i]
       x_8[i + 1] = 0.9*x_1[i] + 2*u[i]
       x_9[i + 1] = 0.9*x_1[i] + 2*u[i]
       x_10[i + 1] = 0.9*x_1[i] + 2*u[i]
       x_11[i + 1] = 0.9*x_1[i] + 2*u[i]
       x_12[i + 1] = 0.9*x_1[i] + 2*u[i]
       x_13[i + 1] = 0.9*x_1[i] + 2*u[i]
       x_14[i + 1] = 0.9*x_1[i] + 2*u[i]
       x_15[i + 1] = 0.9*x_1[i] + 2*u[i]
       x_16[i + 1] = 0.9*x_1[i] + 2*u[i]
       x_17[i + 1] = 0.9*x_1[i] + 2*u[i]
       x_18[i + 1] = 0.9*x_1[i] + 2*u[i]
       x_19[i + 1] = 0.9*x_1[i] + 2*u[i]
       x_20[i + 1] = 0.9*x_1[i] + 2*u[i]
print(f"Shape of x_15:{x_15.shape}")

'''
# Visualize the dataset
h = np.arange(0,1801)
def u_plot (x_axis,y_axis,x_label,y_label):
    plt.figure(figsize = (18, 6))
    plt.plot(x_axis, y_axis, color ='black')
    plt.xlabel(x_label, {'fontsize': 12}) 
    plt.ylabel(y_label, {'fontsize': 12})
u_plot (h,x_1,'h','x_1')
plt.show()
'''

arrays_list = [x_1,x_2,x_3,x_4,x_5,x_6,x_7,x_8,x_9,x_10,
               x_11,x_12,x_13,x_14,x_15,x_16,x_17,x_18,x_19,x_20]

'''
print(f"Shape of combined_x: {combined_x.shape}")
'''


# Create the time series sequences
def time_series_sequence(input_dataset, output_dataset, input_length, output_length): 
    U, y = list(), list()
    for i in range(len(output_dataset)):
        end_iu = i + input_length
        end_oy = end_iu + output_length
        if end_oy > len(output_dataset):
            break
        seq_U, seq_y = input_dataset[i:end_iu].tolist(), output_dataset[end_iu:end_oy].tolist()
        U.append(seq_U)
        y.append(seq_y)
    return np.array(U), np.array(y)


# Split the dataset into train and test


u = u.reshape(1800,1)
train_ind = 1000
y_train_list = []
y_test_list = []
for arrays in arrays_list:
    y_train = arrays[1:train_ind+1]
    y_test = arrays[train_ind+1:]
    y_train_list.append(y_train)
    y_test_list.append(y_test)
print(len(y_train_list))

u_train = u[:train_ind]
u_test = u[train_ind:]

# Create the 3D train, test dataset to feed into LSTM layer.
input_length = 20 
output_length = 5
Y_train_list = []
Y_test_list = []
for arrays in y_train_list:
    U_train, Y_train = time_series_sequence(u_train, arrays, input_length, output_length)
    Y_train_list.append(Y_train)
for arrays in y_test_list:
    U_test, Y_test = time_series_sequence(u_test, arrays, input_length, output_length)
    Y_test_list.append(Y_test)

print(f"Shape of U_train:{U_train.shape}")
print(f"shape of U_test:{U_test.shape}")
Y_train_1 = Y_train_list[0]
Y_train_2 = Y_train_list[1]
combined_Y_train = np.dstack((Y_train_1,Y_train_2))
for i in range(2,20):
    combined_Y_train = np.dstack((combined_Y_train,Y_train_list[i]))
print(f"shape of combined_Y_train:{combined_Y_train.shape}")
Y_test_1 = Y_test_list[0]
Y_test_2 = Y_test_list[1]
combined_Y_test = np.dstack((Y_test_1,Y_test_2))
for i in range(2,20):
    combined_Y_test = np.dstack((combined_Y_test,Y_test_list[i]))
print(f"Shape of combined_Y_test:{combined_Y_test.shape}")
# Now, we have U_train, combined_Y_train, U_test, combined_Y_test
# U_train shape is (976,20,1), combined_Y_train shape is (976,5,20).
# 20 is features, means we have 20 different(now are same) outputs. 


# Build feedforward layer and the LSTM encoder-decoder model
from keras import Input,losses
from keras.losses import Loss
from keras.models import Sequential
from keras.layers import Dense, LSTM, Dropout, RepeatVector, TimeDistributed
from keras.callbacks import ModelCheckpoint
def Reduce_Dimensions_model():
    model = Sequential()
    model.add(Input(shape=(5,20)))
    model.add(Dense(15,activation='linear'))
    model.add(Dense(5,activation='linear'))
    model.add(Dense(1,activation='linear',name="ffloutput"))
    #LSTM encoder_decoder    
    model.add(LSTM(100, activation='sigmoid'))
    model.add(RepeatVector(5))
    model.add(LSTM(100,activation='sigmoid',return_sequences=True))
    model.add(TimeDistributed(Dense(units=1,activation = "linear"),name="finaloutput"))
    return model
model = Reduce_Dimensions_model()
model.summary()
ffl_output = model.get_layer("ffloutput").output
final_output = model.get_layer("finaloutput").output
print(f"Shape of ffl_output:{ffl_output.shape}")
print(f"shape of fianl_output:{final_output.shape}")
def RDloss(ffl_output,final_output):
    loss = tf.keras.losses.MeanSquaredError()
    return loss(ffl_output,final_output)
model.compile(optimizer='adam',loss='RDloss')


# Train and test
Train = model.fit(,epochs=50)


'''
Y_predict = model.predict(U_test)
Y_pred = np.squeeze(Y_predict, axis=2)
Y_pred = Y_pred.flatten()
Y_test = np.squeeze(Y_test,axis=2)
Y_test = Y_test.flatten()


# Visualize the results
fig, ax = plt.subplots(1, 1, figsize=(15, 8))
ax.plot(Y_test, lw=3, c='y', label='test data')
ax.plot(Y_pred, lw=4, c='r',linestyle = ':', label='predictions')
ax.legend(loc="lower left")
plt.show();
'''